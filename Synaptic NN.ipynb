{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and external data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colored\n",
    "from colored import stylize\n",
    "from data import dataloader\n",
    "import datetime\n",
    "import json\n",
    "from neuralnet import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import pixiedust_node #v≥0.2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data from Firebase.\n",
    "Requires [Firebase service account credentials](https://console.firebase.google.com/project/tingle-pilot-collected-data/settings/serviceaccounts/adminsdk) in JSON format saved in `./firebase-credentials`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The default Firebase app already exists. This means you called initialize_app() more than once without providing an app name as the second argument. In most cases you only need to call initialize_app() once. But if you do want to initialize multiple apps, pass a second argument to initialize_app() to give each app a unique name.\n",
      "\u001b[38;5;2mData loaded from Firebase!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pilot_data, notes = dataloader.load_from_firebase(\n",
    "    notes=True,\n",
    "    start=datetime.datetime(2018,3,6,8),\n",
    "    combine=True,\n",
    "    marked=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load [Synaptic](http://caza.la/synaptic/)\n",
    "If \"Error: Cannot find module 'synaptic'\", create and run these two cells:\n",
    "\n",
    "1. ```\n",
    "cd neuralnet\n",
    "```\n",
    "\n",
    "2. ```sh\n",
    "!npm init -y\n",
    "!npm install -s synaptic\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%node\n",
    "var lstm = require('../../tingle-pilot-study/neuralnet/lstm.js');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### See all targets, number of available samples and iteration blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "for target in list(pilot_data.target.unique()):\n",
    "    ib =max(\n",
    "        pilot_data.loc[\n",
    "            pilot_data.target==target\n",
    "        ].iteration_block.dropna()\n",
    "    )\n",
    "    print(\": \".join([\n",
    "        target,\n",
    "        \"{0} on-target samples in {1} iteration block{2}\".format(\n",
    "            str(len(pilot_data.loc[\n",
    "                (pilot_data.target == target) &\n",
    "                (pilot_data.ontarget)\n",
    "            ])),\n",
    "            \"%.0f\" % ib,\n",
    "            \"s\" if ib != 1 else \"\"\n",
    "        )\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Extract training and testing data\n",
    "Define targets of interest and corresponding offtargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     3
    ]
   },
   "outputs": [],
   "source": [
    "with open(\n",
    "    'data/targets.json',\n",
    "    'r'\n",
    ") as fp:\n",
    "    targets = json.load(\n",
    "        fp\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters for nn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_signals = [\n",
    "    \"distance\",\n",
    "    \"thermopile1\",\n",
    "    \"thermopile2\",\n",
    "    \"thermopile3\",\n",
    "    \"thermopile4\"\n",
    "]\n",
    "iteration_blocks = list(range(1,7))\n",
    "n_samples = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get training inputs and outputs, inputs that should evaluate ~true and inputs that should evaluate ~false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3,
     19,
     32
    ]
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "for target in targets:\n",
    "    data[target] = {\n",
    "        \"train\": nn.define_trainer_data(\n",
    "            pilot_data,\n",
    "            {\n",
    "                \"target\": [target],\n",
    "                \"offtarget\": targets[target]\n",
    "            },\n",
    "            input_signals,\n",
    "            iteration_blocks,\n",
    "            n_samples\n",
    "        ),\n",
    "        \"test_true\": nn.define_activation(\n",
    "            pilot_data,\n",
    "            [target],\n",
    "            input_signals,\n",
    "            iteration_blocks,\n",
    "            exclude=n_samples\n",
    "        ),\n",
    "        \"test_false\": nn.define_activation(\n",
    "            pilot_data,\n",
    "            targets[target],\n",
    "            input_signals,\n",
    "            iteration_blocks,\n",
    "            exclude=n_samples\n",
    "        )\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview all inputs and training outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: These data take some time to copy across environments. Give the notebook some time between running cells across Python and JavaScript.\n",
    "\n",
    "---\n",
    "### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%node\n",
    "var networks = {};\n",
    "for (var target in data) {\n",
    "  networks[target] = lstm.train_lstm([5,5,2,1], data[target][\"train\"], 0.06, 0.06, 3000);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%node\n",
    "var test_outputs = {};\n",
    "for (var target in data) {\n",
    "    test_outputs[target] = {\"true\":[],\"false\":[]};\n",
    "    for(var iteration=0; iteration < data[target][\"test_true\"].length; iteration++){\n",
    "      test_outputs[target][\"true\"].push(networks[target].activate(data[target][\"test_true\"][iteration]));\n",
    "      }\n",
    "    for(var iteration=0; iteration < data[target][\"test_false\"].length; iteration++){\n",
    "      test_outputs[target][\"false\"].push(networks[target].activate(data[target][\"test_false\"][iteration]));\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### See outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the training is adequate x ≈ 0 ∀ x in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = {target: [\n",
    "        outputs for outputs in test_outputs[target]['false']\n",
    "] for target in targets}\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the training is adequate x ≈ 1 ∀ x in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = {target: [\n",
    "        outputs for outputs in test_outputs[target]['true']\n",
    "] for target in targets}\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if training is adequate, f ≪ t:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mean = {\n",
    "    target: np.mean(f[target]) for target in targets if target in f and len(f[target])\n",
    "}\n",
    "t_mean = {\n",
    "    target: np.mean(t[target]) for target in targets if target in t and len(t[target])\n",
    "}\n",
    "for target in t_mean:\n",
    "    print(target)\n",
    "    print(\n",
    "        \"f = {0}\\nt = {1}\\n{0} ≪ {1} ?\\n\".format(\n",
    "            str(f_mean[target]),\n",
    "            str(t_mean[target])\n",
    "        ) if f_mean[target] < t_mean[target] else \"f = {0}\\nt = {1}\\n{2}\".format(\n",
    "            str(f_mean[target]),\n",
    "            str(t_mean[target]),\n",
    "            stylize(\n",
    "                \"Nope. f > t\\n\",\n",
    "                colored.fg(\"red\")\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "for target in t_mean:\n",
    "    print(\"{0}: f = {1:.4f} < t = {2:.4f}\".format(\n",
    "        target,\n",
    "        f_mean[target],\n",
    "        t_mean[target]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Try with demo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     3
    ]
   },
   "outputs": [],
   "source": [
    "with open(\n",
    "    'data/demo_data.json',\n",
    "    'r'\n",
    ") as fp:\n",
    "    demo_data = json.load(\n",
    "        fp\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     10
    ]
   },
   "outputs": [],
   "source": [
    "scale = list(\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            a[0:5] for a in [\n",
    "                *demo_data[\"true\"],\n",
    "                *demo_data[\"false\"]\n",
    "            ]\n",
    "        ]\n",
    "    ).astype('float').max(axis=0)\n",
    ")\n",
    "demo_test = {\n",
    "    \"train\":[\n",
    "        *[{\n",
    "            \"input\": [\n",
    "                float(d)/scale[datum_i] for datum_i, d in enumerate(datum[0:5])\n",
    "            ],\n",
    "            \"output\": [1]\n",
    "        } for datum in demo_data[\"true\"][0:40]],\n",
    "        *[{\n",
    "            \"input\": [\n",
    "                float(d)/scale[datum_i] for datum_i, d in enumerate(datum[0:5])\n",
    "            ],\n",
    "            \"output\": [0]\n",
    "        } for datum in demo_data[\"false\"][0:40]]\n",
    "    ],\n",
    "    \"test_true\": [[\n",
    "                float(d)/scale[datum_i] for datum_i, d in enumerate(datum[0:5])\n",
    "            ] for datum in demo_data[\"true\"][41:]],\n",
    "    \"test_false\": [[\n",
    "                float(d)/scale[datum_i] for datum_i, d in enumerate(datum[0:5])\n",
    "            ] for datum in demo_data[\"false\"][41:]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%node\n",
    "var LSTM5 = lstm.train_lstm([5,5,2,1], demo_test[\"train\"], 0.06, 0.06, 3000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%node\n",
    "var demo_test_outputs = {\"true\":[],\"false\":[]}\n",
    "for(var iteration=0; iteration < demo_test[\"test_true\"].length; iteration++){\n",
    "    var op = LSTM5.activate(demo_test[\"test_true\"][iteration]);\n",
    "    demo_test_outputs[\"true\"].push(op);\n",
    "}\n",
    "for(var iteration=0; iteration < demo_test[\"test_false\"].length; iteration++){\n",
    "    demo_test_outputs[\"false\"].push(LSTM5.activate(demo_test[\"test_false\"][iteration]));\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_test_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(demo_test_outputs['false'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(demo_test_outputs['true'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python with Pixiedust (Spark 2.2)",
   "language": "python",
   "name": "pythonwithpixiedustspark22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
