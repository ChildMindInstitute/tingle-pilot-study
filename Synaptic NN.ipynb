{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries and external data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colored\n",
    "from colored import stylize\n",
    "from data import dataloader\n",
    "import datetime\n",
    "import json\n",
    "from neuralnet import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#import pixiedust_node #v≥0.2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data from Firebase.\n",
    "Requires [Firebase service account credentials](https://console.firebase.google.com/project/tingle-pilot-collected-data/settings/serviceaccounts/adminsdk) in JSON format saved in `./firebase-credentials`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mData loaded from Firebase!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pilot_data, notes = dataloader.load_from_firebase(\n",
    "    notes=True,\n",
    "    start=datetime.datetime(2018,3,6,8),\n",
    "    combine=True,\n",
    "    marked=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant1 = dataloader.split_participants(pilot_data)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load [Synaptic](http://caza.la/synaptic/)\n",
    "If \"Error: Cannot find module 'synaptic'\", create and run these two cells:\n",
    "\n",
    "1. ```\n",
    "cd neuralnet\n",
    "```\n",
    "\n",
    "2. ```sh\n",
    "!npm init -y\n",
    "!npm install -s synaptic\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%node\n",
    "var lstm = require('../../tingle-pilot-study/neuralnet/lstm.js');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### See all targets, number of available samples and iteration blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"neuralnet/targets.json\", 'r') as fp:\n",
    "    targets = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{target: training, [all offtarget], [all onbody offtarget], [all nontraining rotation], [all offbody]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in list(pilot_data.target.unique()):\n",
    "    ib =max(\n",
    "        pilot_data.loc[\n",
    "            pilot_data.target==target\n",
    "        ][\"step\"].dropna()\n",
    "    )\n",
    "    print(\": \".join([\n",
    "        target,\n",
    "        \"{0} on-target samples in step {1}\".format(\n",
    "            str(len(pilot_data.loc[\n",
    "                (pilot_data.target == target) &\n",
    "                (pilot_data.ontarget)\n",
    "            ])),\n",
    "            \"%.0f\" % ib\n",
    "        )\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Extract training and testing data\n",
    "Define targets of interest and corresponding offtargets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [
     0,
     3
    ]
   },
   "source": [
    "with open(\n",
    "    'data/targets.json',\n",
    "    'r'\n",
    ") as fp:\n",
    "    targets = json.load(\n",
    "        fp\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters for nn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_signals = [\n",
    "    \"distance\",\n",
    "    \"thermopile1\",\n",
    "    \"thermopile2\",\n",
    "    \"thermopile3\",\n",
    "    \"thermopile4\"\n",
    "]\n",
    "n_samples = [300, 250, 200, 150, 100, 50]\n",
    "steps = list(range(1, 48))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get training inputs and outputs, inputs that should evaluate ~true and inputs that should evaluate ~false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3,
     19,
     32
    ]
   },
   "outputs": [],
   "source": [
    "targ = \"eyebrow\"\n",
    "data = nn.define_trainer_data(\n",
    "    pilot_data,\n",
    "    {\n",
    "        \"target\": [targets[targ]],\n",
    "        \"offtarget\": targets[targ][1]\n",
    "    },\n",
    "    input_signals,\n",
    "    steps,\n",
    "    n_samples=n_samples[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview all inputs and training outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: These data take some time to copy across environments. Give the notebook some time between running cells across Python and JavaScript.\n",
    "\n",
    "---\n",
    "### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%node\n",
    "var networks = {};\n",
    "for n_sample in n_samples:\n",
    "    for (var target in data) {\n",
    "      networks[target] = lstm.train_lstm([5,5,2,1], data[target][\"train\"], 0.06, 0.06, 3000);\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%node\n",
    "var test_outputs = {};\n",
    "for (var target in data) {\n",
    "    test_outputs[target] = {\"true\":[],\"false\":[]};\n",
    "    for(var iteration=0; iteration < data[target][\"test_true\"].length; iteration++){\n",
    "      test_outputs[target][\"true\"].push(networks[target].activate(data[target][\"test_true\"][iteration]));\n",
    "      }\n",
    "    for(var iteration=0; iteration < data[target][\"test_false\"].length; iteration++){\n",
    "      test_outputs[target][\"false\"].push(networks[target].activate(data[target][\"test_false\"][iteration]));\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### See outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_confusion(negative, positive):\n",
    "    \"\"\"\n",
    "    Function to calculate a confusion matrix\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    negative: list of floats\n",
    "        outputs of neural nets with true negative inputs\n",
    "        \n",
    "    positive: list of floats\n",
    "        outputs of neural nets with true positive inputs\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    confusion: matrix of floats\n",
    "        tn, fp, fn, tp\n",
    "        see http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "    \"\"\"\n",
    "    ytrue = [\n",
    "        *[\n",
    "            0 for output in negative\n",
    "        ],\n",
    "        *[\n",
    "            1 for output in positive\n",
    "        ]\n",
    "    ]\n",
    "    ypredicted = [\n",
    "        *[\n",
    "            int(round(o)) for o in negative\n",
    "        ],\n",
    "        *[\n",
    "            int(round(o)) for o in positive\n",
    "        ]\n",
    "    ]\n",
    "    return(confusion_matrix(ytrue, ypredicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the training is adequate x ≈ 0 ∀ x in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = {target: [\n",
    "        outputs for outputs in test_outputs[target]['false']\n",
    "] for target in targets}\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the training is adequate x ≈ 1 ∀ x in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = {target: [\n",
    "        outputs for outputs in test_outputs[target]['true']\n",
    "] for target in targets}\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if training is adequate, f ≪ t:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_mean = {\n",
    "    target: np.mean(f[target]) for target in targets if target in f and len(f[target])\n",
    "}\n",
    "t_mean = {\n",
    "    target: np.mean(t[target]) for target in targets if target in t and len(t[target])\n",
    "}\n",
    "for target in t_mean:\n",
    "    print(target)\n",
    "    print(\n",
    "        \"f = {0}\\nt = {1}\\n{0} ≪ {1} ?\\n\".format(\n",
    "            str(f_mean[target]),\n",
    "            str(t_mean[target])\n",
    "        ) if f_mean[target] < t_mean[target] else \"f = {0}\\nt = {1}\\n{2}\".format(\n",
    "            str(f_mean[target]),\n",
    "            str(t_mean[target]),\n",
    "            stylize(\n",
    "                \"Nope. f > t\\n\",\n",
    "                colored.fg(\"red\")\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "for target in t_mean:\n",
    "    print(\"{0}: f = {1:.4f} < t = {2:.4f}\".format(\n",
    "        target,\n",
    "        f_mean[target],\n",
    "        t_mean[target]\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python with Pixiedust (Spark 2.2)",
   "language": "python",
   "name": "pythonwithpixiedustspark22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
