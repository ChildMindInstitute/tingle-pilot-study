{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data import dataloader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The default Firebase app already exists. This means you called initialize_app() more than once without providing an app name as the second argument. In most cases you only need to call initialize_app() once. But if you do want to initialize multiple apps, pass a second argument to initialize_app() to give each app a unique name.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-5bff1bc5eab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m pilot_data = dataloader.break_out_blocks(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_firebase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m/Users/jake.son/PycharmProjects/tingle-pilot-study/data/dataloader.py\u001b[0m in \u001b[0;36mload_from_firebase\u001b[0;34m(dbURL)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# Initialize the app with a service account, granting admin privileges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     firebase_admin.initialize_app(cred, {\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;34m'databaseURL'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdbURL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     })\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/firebase_admin/__init__.py\u001b[0m in \u001b[0;36minitialize_app\u001b[0;34m(credential, options, name)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DEFAULT_APP_NAME\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         raise ValueError((\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0;34m'The default Firebase app already exists. This means you called '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0;34m'initialize_app() more than once without providing an app name as '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;34m'the second argument. In most cases you only need to call '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The default Firebase app already exists. This means you called initialize_app() more than once without providing an app name as the second argument. In most cases you only need to call initialize_app() once. But if you do want to initialize multiple apps, pass a second argument to initialize_app() to give each app a unique name."
     ]
    }
   ],
   "source": [
    "pilot_data = dataloader.break_out_blocks(\n",
    "    dataloader.load_from_firebase()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none: 19 on-target samples in 2 iteration blocks\n",
      "environment: 106 on-target samples in 4 iteration blocks\n",
      "body: 101 on-target samples in 2 iteration blocks\n",
      "cup: 33 on-target samples in 3 iteration blocks\n",
      "food: 35 on-target samples in 4 iteration blocks\n",
      "nails: 69 on-target samples in 3 iteration blocks\n",
      "smoke: 92 on-target samples in 3 iteration blocks\n",
      "eyebrow: 235 on-target samples in 5 iteration blocks\n",
      "nose: 249 on-target samples in 4 iteration blocks\n",
      "above-ear: 403 on-target samples in 5 iteration blocks\n",
      "behind-ear: 220 on-target samples in 4 iteration blocks\n",
      "opposite-cheek: 74 on-target samples in 6 iteration blocks\n",
      "chin: 166 on-target samples in 1 iteration block\n",
      "cheek: 686 on-target samples in 6 iteration blocks\n",
      "forehead: 176 on-target samples in 1 iteration block\n",
      "top-head: 160 on-target samples in 1 iteration block\n",
      "back-head: 170 on-target samples in 1 iteration block\n",
      "opposite-face: 381 on-target samples in 2 iteration blocks\n",
      "paint-mouth: 81 on-target samples in 3 iteration blocks\n",
      "paint-eyebrow: 82 on-target samples in 3 iteration blocks\n",
      "paint-above-ear: 80 on-target samples in 3 iteration blocks\n",
      "paint-behind-ear: 181 on-target samples in 6 iteration blocks\n",
      "paint-opposite-cheek: 86 on-target samples in 3 iteration blocks\n",
      "ceiling: 25 on-target samples in 2 iteration blocks\n"
     ]
    }
   ],
   "source": [
    "for target in list(pilot_data.target.unique()):\n",
    "    ib =max(\n",
    "        pilot_data.loc[\n",
    "            pilot_data.target==target\n",
    "        ].iteration_block.dropna()\n",
    "    )\n",
    "    print(\": \".join([\n",
    "        target,\n",
    "        \"{0} on-target samples in {1} iteration block{2}\".format(\n",
    "            str(len(pilot_data.loc[\n",
    "                (pilot_data.target == target) &\n",
    "                (pilot_data.ontarget)\n",
    "            ])),\n",
    "            \"%.0f\" % ib,\n",
    "            \"s\" if ib != 1 else \"\"\n",
    "        )\n",
    "    ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pilot_true = []\n",
    "pilot_false = []\n",
    "\n",
    "on_target = 'above-ear'\n",
    "\n",
    "for row in pilot_data[(pilot_data.target == on_target) & (pilot_data.ontarget)][['thermopile1','thermopile2','thermopile3','thermopile4']].values.tolist():\n",
    "    pilot_true.append({'in':row, 'out':1})\n",
    "for row in pilot_data[(pilot_data.target == 'behind-ear') & (pilot_data.ontarget == False)][['thermopile1', 'thermopile2', 'thermopile3', 'thermopile4']].values.tolist():\n",
    "    pilot_false.append({'in':row, 'out':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "on_data = []\n",
    "on_targets = []\n",
    "\n",
    "for piles in pilot_true:\n",
    "    on_data.append([float(x) for x in piles['in']])\n",
    "    on_targets.append(piles['out'])\n",
    "\n",
    "off_data = []\n",
    "off_targets = []\n",
    "\n",
    "for piles in pilot_false:\n",
    "    off_data.append([float(x) for x in piles['in']])\n",
    "    off_targets.append(piles['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 50\n",
    "\n",
    "train_data = []\n",
    "train_data_p = []\n",
    "test_data = []\n",
    "test_data_p = []\n",
    "train_targets = []\n",
    "test_targets = []\n",
    "\n",
    "train_data_p.extend(on_data[:train_size])\n",
    "train_data_p.extend(off_data[:train_size])\n",
    "\n",
    "for row in train_data_p:\n",
    "    row = [np.round(float(x)/98.6,3) for x in row]\n",
    "    train_data.append(row)\n",
    "\n",
    "test_data_p.extend(on_data[train_size:])\n",
    "test_data_p.extend(off_data[train_size:])\n",
    "\n",
    "for row in test_data_p:\n",
    "    row = [np.round(float(x)/98.6,3) for x in row]\n",
    "    test_data.append(row)\n",
    "\n",
    "train_targets.extend(on_targets[:train_size])\n",
    "train_targets.extend(off_targets[:train_size])\n",
    "test_targets.extend(on_targets[train_size:])\n",
    "test_targets.extend(off_targets[train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(25, 15, 5), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='adam', alpha=.001,\n",
    "                    hidden_layer_sizes=(25,15,5), random_state=1)\n",
    "clf.fit(train_data, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate:  0.779\n",
      "True negative rate:  0.949\n",
      "False positive rate: 0.221\n",
      "False negative rate: 0.051\n"
     ]
    }
   ],
   "source": [
    "num_predict = len(test_data)\n",
    "\n",
    "predictions = clf.predict(test_data[:num_predict])\n",
    "accuracy_score(test_targets[:num_predict], predictions)\n",
    "\n",
    "true_pos = []\n",
    "true_neg = []\n",
    "fals_pos = []\n",
    "fals_neg = []\n",
    "\n",
    "count_neg = len([x for x in test_targets if x == 0])\n",
    "count_pos = len([x for x in test_targets if x == 1])\n",
    "\n",
    "for sample in range(len(test_data)):\n",
    "    if test_targets[sample] == 0:\n",
    "        if predictions[sample] == test_targets[sample]:\n",
    "            true_neg.append(sample)\n",
    "        else:\n",
    "            fals_neg.append(sample)\n",
    "    elif test_targets[sample] == 1:\n",
    "        if predictions[sample] == test_targets[sample]:\n",
    "            true_pos.append(sample)\n",
    "        else:\n",
    "            fals_pos.append(sample)\n",
    "        \n",
    "fals_pos = len(fals_pos)/count_pos\n",
    "fals_neg = len(fals_neg)/count_neg\n",
    "true_pos = len(true_pos)/count_pos\n",
    "true_neg = len(true_neg)/count_neg\n",
    "\n",
    "print('Target: ' + str())\n",
    "print('True positive rate:  ' + str(np.round(true_pos,3)))\n",
    "print('True negative rate:  ' + str(np.round(true_neg,3)))\n",
    "print('False positive rate: ' + str(np.round(fals_pos,3)))\n",
    "print('False negative rate: ' + str(np.round(fals_neg,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
